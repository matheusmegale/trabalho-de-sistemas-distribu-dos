# ğŸ“š Recomendador Cultural com Agentes Inteligentes

Sistema distribuÃ­do com dois agentes de IA que classificam perfis culturais e geram recomendaÃ§Ãµes de livros e filmes personalizados, com arquitetura segura e modular em Flask + Docker.

---

## ğŸ” VisÃ£o Geral

Este projeto consiste em:

- Uma **interface web** para entrada de preferÃªncias (nome, idade, gÃªneros, etc.);
- Um **Agente Classificador** que utiliza LLM local (Mistral via GPT4All/Ollama) para analisar o perfil do usuÃ¡rio;
- Um **Agente Recomendador** que gera sugestÃµes baseadas na classificaÃ§Ã£o.

Toda a comunicaÃ§Ã£o Ã© feita via chamadas HTTP, com autenticaÃ§Ã£o entre os agentes e compartilhamento controlado via Docker.

---

## ğŸ¯ Dor (Problema Central)

Em um mundo com acesso ilimitado a filmes, sÃ©ries e livros digitais, os usuÃ¡rios frequentemente se deparam com a chamada â€œparalisia por excesso de escolhaâ€. Com milhares de tÃ­tulos disponÃ­veis em plataformas de streaming e catÃ¡logos online, muitos usuÃ¡rios gastam mais tempo tentando decidir o que consumir do que realmente aproveitando o conteÃºdo. Isso causa frustraÃ§Ã£o, fadiga decisÃ³ria e atÃ© abandono da experiÃªncia. Outro fator agravante Ã© que os sistemas de recomendaÃ§Ã£o atuais, mesmo sofisticados, tendem a se basear exclusivamente em dados comportamentais passados (como cliques, histÃ³rico de visualizaÃ§Ãµes ou compras), sem considerar **as preferÃªncias declaradas pelo prÃ³prio usuÃ¡rio**. Isso limita a capacidade de entregar sugestÃµes realmente significativas. A dor estÃ¡ em nÃ£o se sentir compreendido ou representado pelas recomendaÃ§Ãµes recebidas, o que compromete o engajamento e reduz o valor percebido das plataformas de conteÃºdo.

---

## ğŸ§  ValidaÃ§Ã£o do Problema

O problema da sobrecarga de conteÃºdo nÃ£o Ã© apenas percebido empiricamente; ele Ã© confirmado por dados. Segundo o relatÃ³rio da [Nielsen (2023)](https://www.nielsen.com/insights/2023/data-driven-personalization-2023-state-of-play-report/), **66% dos usuÃ¡rios desistem de consumir conteÃºdo digital por nÃ£o conseguirem escolher o que assistir ou ler**. Isso revela um dÃ©ficit claro de personalizaÃ§Ã£o inteligente nas plataformas. AlÃ©m disso, pesquisas acadÃªmicas, como o estudo de Silva et al. (2022), apontam que o uso de recomendaÃ§Ã£o personalizada com base em perfis declarados pode aumentar o engajamento em atÃ© **47%**. O projeto propÃµe resolver essa lacuna por meio de um sistema distribuÃ­do e modular que permite capturar preferÃªncias declaradas via formulÃ¡rio, processÃ¡-las com um classificador inteligente e gerar recomendaÃ§Ãµes sob medida. Esse fluxo visa restaurar a confianÃ§a do usuÃ¡rio na recomendaÃ§Ã£o automatizada, entregando valor real com base no que ele realmente gosta, e nÃ£o apenas no que ele consumiu no passado.

### Interface de Coleta de PreferÃªncias

A tela abaixo exemplifica o formulÃ¡rio utilizado para entender os gostos do usuÃ¡rio de forma intuitiva. Essa etapa inicial Ã© crucial para o funcionamento do sistema, pois serve como base para a classificaÃ§Ã£o de perfil e a recomendaÃ§Ã£o personalizada:

![image](https://github.com/user-attachments/assets/13a7a731-3365-440c-9a2d-8f18e9335e73)


## ğŸ¬ Exemplo de Funcionamento

O sistema â€œRecomendador Cultural com Agentes Inteligentesâ€ coleta preferÃªncias culturais do usuÃ¡rio por meio de uma interface web simples e responsiva, e entrega recomendaÃ§Ãµes personalizadas com base em seu perfil classificado.

### ğŸ“ Preenchimento do FormulÃ¡rio

O usuÃ¡rio informa nome, idade, tipo de mÃ­dia preferida (filmes, livros ou ambos) e os gÃªneros culturais favoritos.

![Captura de tela 2025-07-08 141233](https://github.com/user-attachments/assets/f3f564a6-7525-48cb-9200-6ddf335b3a04)

---

### ğŸ¤– Resultado: Perfil + RecomendaÃ§Ãµes Inteligentes

ApÃ³s o envio, o sistema classifica o perfil automaticamente e exibe 10 recomendaÃ§Ãµes personalizadas, utilizando IA local (Ollama + Mistral) e a API da OpenAI.

![Captura de tela 2025-07-08 142437](https://github.com/user-attachments/assets/111a46e5-a445-47f4-9def-ada19cb3cf4a)

---

## ğŸ§± Arquitetura

Ver documentos:

[VisÃ£o Inicial PrÃ©-Modelagem de AmeaÃ§as.pdf](https://github.com/user-attachments/files/21132117/Visao.Inicial.Pre-Modelagem.de.Ameacas.pdf)

[VisÃ£o Final ApÃ³s ImplementaÃ§Ã£o das Medidas de MitigaÃ§Ã£o.pdf](https://github.com/user-attachments/files/21132210/Visao.Final.Apos.Implementacao.das.Medidas.de.Mitigacao.pdf)

---

## ğŸš€ Como executar o projeto

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/matheusmegale/trabalho-de-sistemas-distribu-dos.git
cd trabalho-de-sistemas-distribu-dos/recomendador
```

### 2. Instale o Ollama

O Ollama permite rodar modelos LLM localmente de forma eficiente.

Acesse: https://ollama.com/download

Instale o programa para seu sistema operacional.

ApÃ³s instalar, execute:

```bash
ollama run mistral
```

### 3. Crie o arquivo .env

Crie um arquivo .env na raiz com sua chave da OpenAI (se desejar usar a API) e o token interno:

```env
OPENAI_API_KEY=sk-sua-chave-aqui
INTERNAL_API_TOKEN=chave_secreta_compartilhada
```

### 4. Instale dependÃªncias (modo local)

Se preferir rodar sem Docker:

```bash
pip install -r requirements.txt
```

Execute com Docker Compose:

```bash
docker-compose up --build
```

Esse comando irÃ¡:

   â€¢ Criar rede privada entre os containers;

   â€¢ Subir Gateway (porta 5000);

   â€¢ Subir Classificador;

   â€¢ Compartilhar arquivos em /shared.

 Acesse `http://localhost:5000` no navegador.

---

### ğŸ§ª Testando o Sistema

Preencha o formulÃ¡rio com seus dados;

Clique em â€œEnviar PreferÃªnciasâ€;

O sistema irÃ¡:

  â€¢ Salvar as preferÃªncias como JSON;

  â€¢ Enviar para o Agente Classificador;

  â€¢ Obter o perfil via IA local (Mistral);

  â€¢ Retornar recomendaÃ§Ãµes com base nesse perfil.

## ğŸ“ Estrutura de Pastas

```bash
recomendador/
â”œâ”€â”€ classificador/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ classificador.py
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ gateway_api/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ recomendador_ia.py
â”‚   â””â”€â”€ templates/index.html
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âœ… Funcionalidades

* [x] Interface web com formulÃ¡rio de entrada
* [x] Salvamento de preferÃªncias em JSON
* [x] ClassificaÃ§Ã£o de perfil via modelo LLM local (Agente 1)
* [x] GeraÃ§Ã£o de recomendaÃ§Ãµes personalizadas (Agente 2)
* [x] ComunicaÃ§Ã£o via API com autenticaÃ§Ã£o entre serviÃ§os
* [x] Isolamento por containers Docker e rede privada

---

## ğŸ›¡ï¸ SeguranÃ§a

* Uso de `.env` para proteger chaves sensÃ­veis;
* Header interno `X-Internal-Token` entre containers;
* Rede privada com controle de acesso entre agentes;
* Volume compartilhado com escopo restrito.

---

## ğŸ“ ReferÃªncias

* Nielsen, The Era of Choice Report â€“ 2023
* Silva et al., â€œSistemas Inteligentes de RecomendaÃ§Ã£o Baseados em Perfilâ€, UFSC, 2022
* OpenAI API Docs â€“ [https://platform.openai.com/docs](https://platform.openai.com/docs)
* Ollama â€“ [https://ollama.com/](https://ollama.com/)
* Flask Documentation â€“ [https://flask.palletsprojects.com/](https://flask.palletsprojects.com/)

---

## ğŸ‘¨â€ğŸ’» Desenvolvido por

* Eduardo Ruan GuimarÃ£es Fonseca â€“ Sistemas de InformaÃ§Ã£o â€“ UFLA
* Izac Moreira Souza Junior â€“ Sistemas de InformaÃ§Ã£o â€“ UFLA
* Matheus de Paula Megale â€“ Sistemas de InformaÃ§Ã£o â€“ UFLA
* Nadson Souza Matos  â€“ Sistemas de InformaÃ§Ã£o â€“ UFLA

