# ğŸ“š Recomendador Cultural com Agentes Inteligentes

Sistema distribuÃ­do com dois agentes de IA que classificam perfis culturais e geram recomendaÃ§Ãµes de livros e filmes personalizados, com arquitetura segura e modular em Flask + Docker.

---

## ğŸ” VisÃ£o Geral

Este projeto consiste em:

- Uma **interface web** para entrada de preferÃªncias (nome, idade, gÃªneros, etc.);
- Um **Agente Classificador** que utiliza LLM local (Mistral via GPT4All/Ollama) para analisar o perfil do usuÃ¡rio;
- Um **Agente Recomendador** que gera sugestÃµes baseadas na classificaÃ§Ã£o.

Toda a comunicaÃ§Ã£o Ã© feita via chamadas HTTP, com autenticaÃ§Ã£o entre os agentes e compartilhamento controlado via Docker.

---

## ğŸ§  ValidaÃ§Ã£o do Problema

### RelevÃ¢ncia do problema abordado

A sobrecarga de conteÃºdo digital dificulta a escolha de livros e filmes alinhados ao gosto do usuÃ¡rio. Muitos sistemas de recomendaÃ§Ã£o existentes utilizam apenas histÃ³rico de navegaÃ§Ã£o, sem considerar preferÃªncias declaradas de forma personalizada.

Este projeto busca resolver essa dor combinando:

- Um formulÃ¡rio intuitivo de preferÃªncias culturais;
- ClassificaÃ§Ã£o de perfil com IA local (LLM);
- RecomendaÃ§Ãµes geradas com base no perfil detectado.

Segundo dados da [Nielsen](https://www.nielsen.com/us/en/insights/report/2023/the-era-of-choice/), 66% dos usuÃ¡rios desistem de consumir conteÃºdo por excesso de opÃ§Ãµes. AlÃ©m disso, estudos acadÃªmicos demonstram que sistemas de recomendaÃ§Ã£o personalizados aumentam o engajamento em atÃ© 47% (Silva et al., 2022).

### Interface de Coleta de PreferÃªncias

A tela abaixo exemplifica o formulÃ¡rio utilizado para entender os gostos do usuÃ¡rio de forma intuitiva. Essa etapa inicial Ã© crucial para o funcionamento do sistema, pois serve como base para a classificaÃ§Ã£o de perfil e a recomendaÃ§Ã£o personalizada:

![image](https://github.com/user-attachments/assets/13a7a731-3365-440c-9a2d-8f18e9335e73)

### DocumentaÃ§Ã£o da "dor" a ser resolvida

O sistema visa resolver:

- A dificuldade dos usuÃ¡rios em encontrar conteÃºdo relevante de forma rÃ¡pida;
- A falta de personalizaÃ§Ã£o de sistemas tradicionais;
- A ausÃªncia de soluÃ§Ãµes com uso de IA local, que respeitem privacidade.

Com isso, o projeto entrega uma experiÃªncia adaptativa e confiÃ¡vel mesmo em contextos com acesso restrito Ã  internet ou onde privacidade Ã© essencial.

---

## ğŸ§± Arquitetura

Ver documentos:

COLOCAR OS DOCUMENTOS AQUI

---

## ğŸš€ Como executar o projeto

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/matheusmegale/trabalho-de-sistemas-distribu-dos.git
cd trabalho-de-sistemas-distribu-dos/recomendador
```

### 2. Instale o Ollama

O Ollama permite rodar modelos LLM localmente de forma eficiente.

Acesse: https://ollama.com/download

Instale o programa para seu sistema operacional.

ApÃ³s instalar, execute:

```bash
ollama run mistral
```

### 3. Crie o arquivo .env

Crie um arquivo .env na raiz com sua chave da OpenAI (se desejar usar a API) e o token interno:

```env
OPENAI_API_KEY=sk-sua-chave-aqui
INTERNAL_API_TOKEN=chave_secreta_compartilhada
```

### 4. Instale dependÃªncias (modo local)

Se preferir rodar sem Docker:

```bash
pip install -r requirements.txt
```

Execute com Docker Compose:

```bash
docker-compose up --build
```

Esse comando irÃ¡:

Criar rede privada entre os containers;

Subir Gateway (porta 5000);

Subir Classificador;

Compartilhar arquivos em /shared.

 Acesse `http://localhost:5000` no navegador.

---

### ğŸ§ª Testando o Sistema

Preencha o formulÃ¡rio com seus dados;

Clique em â€œEnviar PreferÃªnciasâ€;

O sistema irÃ¡:

Salvar as preferÃªncias como JSON;

  â€¢ Enviar para o Agente Classificador;

  â€¢ Obter o perfil via IA local (Mistral);

  â€¢ Retornar recomendaÃ§Ãµes com base nesse perfil.

## ğŸ“ Estrutura de Pastas

```bash
recomendador/
â”œâ”€â”€ classificador/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ classificador.py
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ gateway_api/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ recomendador_ia.py
â”‚   â””â”€â”€ templates/index.html
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âœ… Funcionalidades

* [x] Interface web com formulÃ¡rio de entrada
* [x] Salvamento de preferÃªncias em JSON
* [x] ClassificaÃ§Ã£o de perfil via modelo LLM local (Agente 1)
* [x] GeraÃ§Ã£o de recomendaÃ§Ãµes personalizadas (Agente 2)
* [x] ComunicaÃ§Ã£o via API com autenticaÃ§Ã£o entre serviÃ§os
* [x] Isolamento por containers Docker e rede privada

---

## ğŸ›¡ï¸ SeguranÃ§a

* Uso de `.env` para proteger chaves sensÃ­veis;
* Header interno `X-Internal-Token` entre containers;
* Rede privada com controle de acesso entre agentes;
* Volume compartilhado com escopo restrito.

---

## ğŸ“ ReferÃªncias

* Nielsen, The Era of Choice Report â€“ 2023
* Silva et al., â€œSistemas Inteligentes de RecomendaÃ§Ã£o Baseados em Perfilâ€, UFSC, 2022
* OpenAI API Docs â€“ [https://platform.openai.com/docs](https://platform.openai.com/docs)
* Ollama â€“ [https://ollama.com/](https://ollama.com/)
* Flask Documentation â€“ [https://flask.palletsprojects.com/](https://flask.palletsprojects.com/)

---

## ğŸ‘¨â€ğŸ’» Desenvolvido por

Eduardo Ruan GuimarÃ£es Fonseca â€“ Sistemas de InformaÃ§Ã£o â€“ UFLA
Izac Moreira Souza Junior â€“ Sistemas de InformaÃ§Ã£o â€“ UFLA
Matheus de Paula Megale â€“ Sistemas de InformaÃ§Ã£o â€“ UFLA
Nadson Souza Matos  â€“ Sistemas de InformaÃ§Ã£o â€“ UFLA

